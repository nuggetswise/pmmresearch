#!/usr/bin/env python3
"""
Test script to compare all three prompts with the same query
"""

import asyncio
import json
from datetime import datetime
from deep_research import research_agent
from advanced_research import advanced_researcher
from prompt_manager import prompt_manager

def test_all_prompts():
    """Test all three prompts with the same query"""
    
    query = "Sage Intacct wants to focus on selling to SMB & Mid sized Healthcare companies. What is the competition that we could come across in this space"
    
    print("🧪 Testing all three prompts with the same query...")
    print(f"Query: {query}")
    print("=" * 80)
    
    results = {}
    
    # Test testprompt1 (basic research)
    print("\n📋 Testing testprompt1 (Basic Research)...")
    try:
        result1 = research_agent.generate_research_report(query, "testprompt1")
        results["testprompt1"] = result1
        print("✅ testprompt1 completed")
    except Exception as e:
        print(f"❌ testprompt1 failed: {e}")
        results["testprompt1"] = {"error": str(e)}
    
    # Test testprompt3 (advanced 3-stage)
    print("\n📋 Testing testprompt3 (Advanced 3-Stage Research)...")
    try:
        result3 = asyncio.run(advanced_researcher.conduct_advanced_research(query, "testprompt3"))
        results["testprompt3"] = result3
        print("✅ testprompt3 completed")
    except Exception as e:
        print(f"❌ testprompt3 failed: {e}")
        results["testprompt3"] = {"error": str(e)}
    
    # Test testprompt4 (data-driven)
    print("\n📋 Testing testprompt4 (Data-Driven Research)...")
    try:
        result4 = research_agent.generate_research_report(query, "testprompt4")
        results["testprompt4"] = result4
        print("✅ testprompt4 completed")
    except Exception as e:
        print(f"❌ testprompt4 failed: {e}")
        results["testprompt4"] = {"error": str(e)}
    
    return results

def generate_comparison_markdown(results, query):
    """Generate a markdown file comparing all three results"""
    
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    markdown_content = f"""# PMM Research Agent - Prompt Comparison Test

**Query:** {query}  
**Test Date:** {timestamp}  
**Purpose:** Compare output quality and approach across all three prompts

---

## 📊 Test Overview

This test compares the output of three different research prompts:
- **testprompt1**: Basic research with structured 3-step approach
- **testprompt3**: Advanced 3-stage pipeline with sophisticated orchestration  
- **testprompt4**: Data-driven research using web sources

---

## 🔍 Query Details

**Original Query:** {query}

**Context:** Sage Intacct wants to focus on selling to SMB & Mid-sized Healthcare companies. We need to identify the competitive landscape in this space.

---

## 📋 Results Comparison

"""
    
    # Add results for each prompt
    for prompt_name, result in results.items():
        markdown_content += f"### {prompt_name.upper()}\n\n"
        
        if "error" in result:
            markdown_content += f"**Status:** ❌ Failed\n"
            markdown_content += f"**Error:** {result['error']}\n\n"
        else:
            markdown_content += f"**Status:** ✅ Success\n"
            markdown_content += f"**Model:** {result.get('model', 'Unknown')}\n"
            markdown_content += f"**Sources Used:** {result.get('sources_used', result.get('total_sources', 'Unknown'))}\n"
            markdown_content += f"**Research Type:** {result.get('research_type', 'standard')}\n\n"
            
            # Add the content
            content = result.get('content', 'No content available')
            markdown_content += f"**Output:**\n\n{content}\n\n"
        
        markdown_content += "---\n\n"
    
    # Add analysis section
    markdown_content += """## 📈 Analysis & Observations

### Key Differences Observed:

1. **Approach & Methodology**
   - testprompt1: 
   - testprompt3: 
   - testprompt4: 

2. **Source Quality & Quantity**
   - testprompt1: 
   - testprompt3: 
   - testprompt4: 

3. **Output Structure & Format**
   - testprompt1: 
   - testprompt3: 
   - testprompt4: 

4. **Strategic Depth & Insights**
   - testprompt1: 
   - testprompt3: 
   - testprompt4: 

### Recommendations:

- **Best for Quick Research:** 
- **Best for Deep Analysis:** 
- **Best for Executive Reports:** 

---

## 🎯 Production Readiness Assessment

- **Consistency:** 
- **Citation Quality:** 
- **Strategic Value:** 
- **Format Standardization:** 

---

*Generated by PMM Research Agent Test Suite*
"""
    
    return markdown_content

def main():
    """Main test function"""
    print("🚀 Starting PMM Research Agent Prompt Comparison Test")
    print("=" * 60)
    
    # Run the tests
    results = test_all_prompts()
    
    # Generate comparison markdown
    query = "Sage Intacct wants to focus on selling to SMB & Mid sized Healthcare companies. What is the competition that we could come across in this space"
    markdown_content = generate_comparison_markdown(results, query)
    
    # Save to file
    filename = f"prompt_comparison_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(markdown_content)
    
    print(f"\n✅ Test completed! Results saved to: {filename}")
    print(f"📊 Generated comparison markdown with {len(results)} prompt results")
    
    # Print summary
    print("\n📋 Summary:")
    for prompt_name, result in results.items():
        status = "✅ Success" if "error" not in result else "❌ Failed"
        print(f"   {prompt_name}: {status}")

if __name__ == "__main__":
    main() 